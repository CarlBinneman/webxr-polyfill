<html>
	<head>
		<title>AR anchor example</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<style>
			body, html {
				padding: 0;
				margin: 0;
				width: 100%;
				height: 100%;
				-webkit-user-select: none;
				user-select: none;
			}
			#target {
				width: 100%;
				height: 100%;
				position: absolute;
			}
			.text-box {
				position: absolute;
				top: 5%;
				left: 50%;
				color: white;
				background: rgba(27,55,55,0.75);;
				outline: 1px solid rgba(127,255,255,0.75);
				border: 0px;
				padding: 5px 10px;
				transform: translate(-50%, 0%);
				font-size: 0.8em;
			}
			.common-message {
				position: absolute;
				top: 50%;
				left: 50%;
				transform: translate(-50%, -50%);
				font-size: 10px;
			}
			img.crosshair {
				position: absolute;
				top: 50%;
				left: 50%;
				margin-left: -32px;
				margin-top: -32px;
			}
		</style>
		<link rel="stylesheet" href="../common.css"/>
		<script src="../libs/three.js"></script>
		<script src="../libs/stats.js"></script>
		<script type="module" src="../../polyfill/XRPolyfill.js"></script>
		<script nomodule src="../../dist/webxr-polyfill.js"></script>
		<script src="../common.js"></script>
	</head>
	<body>
		<img src="target-28139_64.png" class="crosshair" />
		<div id="target" />
		<div onclick="hideMe(this)" id="description">
			<h2>Simple Computer Vision</h2>
			<h5>(click to dismiss)</h5>
			<p>Compute the average intensity of the video image pixels.</p>
		</div>
		<script id="worker1" type="javascript/worker">

			/**
			 * In the video callback,  ev.detail contains:
				{
				"frame": {
					"buffers": [ // Array of base64 encoded string buffers
					{
						"size": {
						"width": 320,
						"height": 180,
						"bytesPerRow": 320,
						"bytesPerPixel": 1
						},
						"buffer": "e3x...d7d"   /// convert to Uint8 ArrayBuffer in code below
					},
					{
						"size": {
						"width": 160,
						"height": 90,
						"bytesPerRow": 320,
						"bytesPerPixel": 2
						},
						"buffer": "ZZF.../fIJ7"  /// convert to Uint8 ArrayBuffer in code below
					}
					],
					"pixelFormatType": "kCVPixelFormatType_420YpCbCr8BiPlanarFullRange",
					"pixelFormat": "YUV420P",  /// Added in the code below, clients should ignore pixelFormatType
					"timestamp": 337791
				},
				"camera": {
					"cameraIntrinsics": [3x3 matrix],
						fx 0   px
						0  fy  py
						0  0   1
						fx and fy are the focal length in pixels.
						px and py are the coordinates of the principal point in pixels.
						The origin is at the center of the upper-left pixel.

					"cameraImageResolution": {
					"width": 1280,
					"height": 720
					},
					"viewMatrix": [4x4 camera view matrix],
					"interfaceOrientation": 3,
						// 0 UIDeviceOrientationUnknown
						// 1 UIDeviceOrientationPortrait
						// 2 UIDeviceOrientationPortraitUpsideDown
						// 3 UIDeviceOrientationLandscapeRight
						// 4 UIDeviceOrientationLandscapeLeft
					"projectionMatrix": [4x4 camera projection matrix]
				}
				}
			*/

			var intensity = 0.0;
			var cr = -1;
			var cb = -1;

			averageIntensity = function (buffer) {
				var w = buffer.size.width;
				var h = buffer.size.height;
				var pad = buffer.size.bytesPerRow - w;
				var pixels = new Uint8Array(buffer.buffer);
			
				intensity = 0.0;
				var p = 0;
				for (var r = 0; r < h; r++) {
					var v = 0;
					for (var i = 0; i < w; i++) {
						if (p < pixels.length) {
							v += pixels[p++]
						} else {
							console.error("overflow pixel buffer")
						}
					}
					intensity += v / w;
					p += pad;
				}			
				intensity = (intensity / h) / 255.0;
			}
			
			colorAtCenter = function(buffer) {
				var w = buffer.size.width;
				var h = buffer.size.height;
				var pixels = new Uint8Array(buffer.buffer);

				var cx = Math.floor(w / 2) * buffer.size.bytesPerPixel
				var cy = Math.floor(h / 2)
				var p = cy * buffer.size.bytesPerRow + cx;
				cb = pixels[p++];
				cr = pixels[p];
			}

			self.addEventListener('message',  function(event){
				var frame = event.data.frame
				var camera = event.data.camera
				switch (frame.pixelFormat) {
					case "YUV420P":
					this.averageIntensity(frame.buffers[0])
					this.colorAtCenter(frame.buffers[1])

					// pass the buffers back or they will be garbage collected
					var buffers = frame.buffers
					var buffs = []
					for (var i = 0; i < buffers.length; i++) {
						buffs.push(buffers[i].buffer)
					}
	
					postMessage ({intensity: intensity, cr: cr, cb: cb, buffers: buffs, frame: frame}, buffs);
				}
			});
			
			// setInterval( function(){
			//     console.log("Help me!")
			//     self.postMessage (Math.random() * 255.0);
			//}, 500);
		</script>
		<script>
			// RAINBOW Candy of a Certain Name colors
			var colors = [
				{ cr:  230, cb: 100, name: "RED" },
				{ cr:  71, cb: 71, name: "GREEN" },
				{ cr:  152, cb: 33, name: "YELLOW" }
			] 
			var beginTime = ( performance || Date ).now(), prevTime = beginTime, frames = 0;
			
			var stats = new Stats();
			stats.domElement.style.cssText = 'position:fixed;top:2%;right:2%;cursor:pointer;opacity:0.9;z-index:10000';
			var cvPanel = stats.addPanel( new Stats.Panel( 'CV fps', '#ff8', '#221' ) );
			stats.showPanel( 2 ); // 0: fps, 1: ms, 2: mb, 3+: custom

			var updateCVFPS = function () {
				frames ++;
				var time = ( performance || Date ).now();
				if ( time >= prevTime + 1000 ) {
					cvPanel.update( ( frames * 1000 ) / ( time - prevTime ), 100 );
					prevTime = time;
					frames = 0;
				}
				beginTime = time;
			}

			// flag to set true if you want to construct a texture from the UV image 
			var makeTexUV = false;

			document.body.appendChild( stats.dom );

			class ARAnchorExample extends XRExampleBase {
				constructor(domElement){
					super(domElement, false, true, true)


					this.textBox = document.createElement('span')
					this.textBox.setAttribute('class', 'text-box')
					this.textBox.innerText = '0.0'
					this.intensity = 0;
					this.cr = 0;
					this.cb = 0;
					this.lightEstimate = 0;
					this.el.appendChild(this.textBox)
				}

				newSession() {
					var blob = new Blob([
						document.querySelector('#worker1').textContent
					], { type: "text/javascript" })

					this.worker = new Worker(window.URL.createObjectURL(blob));
					
					var self = this;
					this.worker.onmessage = function(ev) {
						self.intensity = ev.data.intensity;
						self.cr = ev.data.cr;
						self.cb = ev.data.cb;
						self.handleVisionDone(ev.data.frame, ev.data.buffers);
					}
					
					this.worker.addEventListener('error', (e) => { 
						console.log("worker error:" + e) 
					})

					//this.setVideoWorker(this.worker);
					this.setVideoWorker(ev => { this.handleVideoFrame(ev) })
				}

				// Called during construction
				initializeScene(){
					// make and display an image of the UV image buffer
					if (makeTexUV) {
						var size = 4;
						var data = new Uint8Array( 12 );
						for ( var i = 0; i < 12; i ++ ) {
							data[i] = 255 / (i + 1);
						}
						this.texBuff = data;
						this.texSize = 12;
						this.uvTexture = new THREE.DataTexture( data, 2, 2, THREE.RGBFormat );
						this.uvTexture.needsUpdate = true;

						var geometry = new THREE.PlaneGeometry(1, 1);
						var material = new THREE.MeshBasicMaterial( {color: 0xff00ff88, map: this.uvTexture, side: THREE.DoubleSide } );
						var plane = new THREE.Mesh( geometry, material );
						var mat = new THREE.Matrix4();
						mat = mat.makeScale(0.1,0.1,0.1);
						mat = mat.setPosition(new THREE.Vector3(-.05,0.0,-.33))
						plane.applyMatrix(mat)
						this.camera.add( plane );
					}

					// Add a box at the scene origin
					let box = new THREE.Mesh(
						new THREE.BoxBufferGeometry(0.1, 0.1, 0.1),
						new THREE.MeshPhongMaterial({ color: '#DDFFDD' })
					)
					box.position.set(0, 0, 0)
					this.floorGroup.add(box)

					this.scene.add(new THREE.AmbientLight('#FFF', 0.2))
					let directionalLight = new THREE.DirectionalLight('#FFF', 0.6)
					directionalLight.position.set(0, 10, 0)
					this.scene.add(directionalLight)
				}

				updateScene(frame){
					this.lightEstimate = frame.lightEstimate || 0;
					stats.update()
					if (this.messageText != this.textBox.innerHTML) {
						this.textBox.innerHTML = this.messageText;
					}
				}

						
				handleVisionDone(frame, buffers) {
					var txt = "ARKit Light Estimate: " + this.lightEstimate.toFixed(2) + "<br>CV Average Intensity: " + this.intensity.toFixed(2)
					+ "<br>Center R/B: " + this.cr.toFixed(2) + " / " + this.cb.toFixed(2) + "<br><center>";
					
					for (var i=0; i<colors.length; i++) {
						var c = colors[i];
						c.dist = Math.sqrt((c.cr - this.cr) * (c.cr - this.cr) + (c.cb - this.cb)*(c.cb - this.cb));
						txt += c.dist.toFixed(1) + " " 
					}
					for (i=0; i<colors.length; i++) {
						c = colors[i];
						if (c.dist < 30) {
							txt += "<br><br>TASTE THE<br>RAINBOW!<br><h2>" + c.name + "</h2>"; 
						} 
					}
					txt+="</center>"

					this.messageText = txt;

					if (makeTexUV) {
						var buffer = frame.buffers[1];
						var buff = buffer.buffer;
						if (this.texSize != (buff.byteLength /2 *3)) {
							this.texSize = buff.byteLength /2 * 3
							this.texBuff = new Uint8Array( this.texSize );  // convert each pixel from 2 to 3 bytes
						}
						
						var j = 0;
						var pixels = new Uint8Array(buff);
						for ( var i = 0; i < this.texSize; i ++ ) {
							this.texBuff[i] = pixels[j++];
							i++;
							this.texBuff[i] = 0;
							i++;
							this.texBuff[i] = pixels[j++];
						}
						this.uvTexture.image = { data: this.texBuff, width: buffer.size.width, height: buffer.size.height };
						this.uvTexture.needsUpdate = true;
					}							
					updateCVFPS();
					this.requestVideoFrame(buffers);
				}

				//////
				////// NOT USED with worker above, but can switch to callback model using these
				//////
				averageIntensity(buffer) {
					var w = buffer.size.width;
					var h = buffer.size.height;
					var pad = buffer.size.bytesPerRow - w;
					var pixels = new Uint8Array(buffer.buffer);

					var intensity = 0.0;
					var p = 0;
					for (var r = 0; r < h; r++) {
						var v = 0;
						for (var i = 0; i < w; i++) {
							if (p < pixels.length) {
								v += pixels[p++]
							} else {
								console.error("overflow pixel buffer")
							}
						}
						intensity += v / w;
						p += pad;
					}
					this.intensity = (intensity / h) / 255.0;
				}

				colorAtCenter(buffer) {
					var w = buffer.size.width;
					var h = buffer.size.height;
					var pixels = new Uint8Array(buffer.buffer);

					var cx = Math.floor(w / 2) * buffer.size.bytesPerPixel
					var cy = Math.floor(h / 2)
					var p = cy * buffer.size.bytesPerRow + cx;
					this.cb = pixels[p++];
					this.cr = pixels[p];
				}

				handleVideoFrame(ev) {
					var frame = ev.detail.frame
					var camera = ev.detail.camera
					switch (frame.pixelFormat) {
						case "YUV420P":
						this.averageIntensity(frame.buffers[0])
						this.colorAtCenter(frame.buffers[1])
					}

					// pass the buffers back or they will be garbage collected
					var buffers = frame.buffers
					var buffs = []
					for (var i = 0; i < buffers.length; i++) {
						buffs.push(buffers[i].buffer)
					}	
					this.handleVisionDone(frame, buffers);
				}

			}

			window.addEventListener('DOMContentLoaded', () => {
				setTimeout(() => {
					try {
						window.pageApp = new ARAnchorExample(document.getElementById('target'))
					} catch(e) {
						console.error('page error', e)
					}
				}, 1000)
			})
		</script>
	</body>
</html>
